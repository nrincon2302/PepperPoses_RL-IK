@article{kroemer2021review,
	author = {Kroemer, O. and Niekum, S. and Konidaris, G.},
	title = {A review of robot learning for manipulation: Challenges, representations, and algorithms},
	journal = {Journal of Machine Learning Research},
	volume = {22},
	number = {1},
	pages = {1--82},
	year = {2021},
	note = {\url{https://www.jmlr.org/papers/volume22/19-804/19-804.pdf}}
}

@misc{schulman2017ppo,
	author = {Schulman, J. and Wolski, F. and Dhariwal, P. and Radford, A. and Klimov, O.},
	title = {Proximal Policy Optimization Algorithms},
	year = {2017},
	url = {https://arxiv.org/pdf/1707.06347}
}

@article{haarnoja2018sac,
	author  = {Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
	title   = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
	journal = {arXiv preprint arXiv:1801.01290},
	year    = {2018},
	doi     = {10.48550/arXiv.1801.01290},
	url     = {https://arxiv.org/abs/1801.01290}
}

@misc{softbank2023pepper,
	author = {{SoftBank Robotics}},
	title = {Pepper: The humanoid robot (Product Documentation)},
	year = {2023},
	url = {https://aldebaran.com/en/pepper/}
}

@book{sutton2018reinforcement,
	author = {Sutton, R. S. and Barto, A. G.},
	title = {Reinforcement Learning: An Introduction},
	edition = {2},
	year = {2018},
	publisher = {MIT Press}
}

@article{bauerle2010markov,
	author       = {Nicole Bäuerle and Ulrich Rieder},
	title        = {Markov Decision Processes},
	journal      = {Jahresbericht der Deutschen Mathematiker-Vereinigung},
	volume       = {112},
	number       = {4},
	pages        = {217--243},
	year         = {2010},
	doi          = {10.1365/s13291-010-0007-2},
	url          = {https://doi.org/10.1365/s13291-010-0007-2},
	issn         = {1869-7135}
}

@online{nekamiche2023curriculum,
	author       = {Noha Nekamiche},
	title        = {Curriculum Learning},
	year         = {2023},
	month        = may,
	day          = {12},
	url          = {https://medium.com/aiguys/curriculum-learning-83b1b2221f33},
	urldate      = {2025-06-23},
	organization = {AIGuys (Medium)},
	note         = {Publicado en Medium}
}

@ARTICLE{ozalp2024advancements,
	author={Ozalp, Recep and Ucar, Aysegul and Guzelis, Cuneyt},
	journal={IEEE Access}, 
	title={Advancements in Deep Reinforcement Learning and Inverse Reinforcement Learning for Robotic Manipulation: Toward Trustworthy, Interpretable, and Explainable Artificial Intelligence}, 
	year={2024},
	volume={12},
	number={},
	pages={51840-51858},
	keywords={Robots;Artificial intelligence;Task analysis;Robot kinematics;Classification algorithms;Explainable AI;Deep reinforcement learning;Inverse problems;Manipulators;Trusted computing;Deep reinforcement learning;inverse reinforcement learning;robotic manipulation;artificial intelligence;trustworthy AI;interpretable AI;eXplainable AI},
	doi={10.1109/ACCESS.2024.3385426}}

@article{weng2020curriculum,
	title   = {Curriculum for Reinforcement Learning},
	author  = {Lilian Weng},
	journal = {lilianweng.github.io},
	year    = {2020},
	month   = {Jan},
	url     = {https://lilianweng.github.io/posts/2020-01-29-curriculum-rl/}
}

@Article{malik2022deeprl,
	AUTHOR = {Malik, Aryslan and Lischuk, Yevgeniy and Henderson, Troy and Prazenica, Richard},
	TITLE = {A Deep Reinforcement-Learning Approach for Inverse Kinematics Solution of a High Degree of Freedom Robotic Manipulator},
	JOURNAL = {Robotics},
	VOLUME = {11},
	YEAR = {2022},
	NUMBER = {2},
	ARTICLE-NUMBER = {44},
	URL = {https://www.mdpi.com/2218-6581/11/2/44},
	ISSN = {2218-6581},
	DOI = {10.3390/robotics11020044}
}

@article{liu2021deep,
	author  = {Rongrong Liu and Florent Nageotte and Philippe Zanne and Michel de Mathelin and Birgitta Dresp-Langley},
	title   = {Deep Reinforcement Learning for the Control of Robotic Manipulation: A Focussed Mini-Review},
	journal = {Robotics},
	volume  = {10},
	number  = {1},
	pages   = {22},
	year    = {2021},
	doi     = {10.3390/robotics10010022},
	url     = {https://doi.org/10.3390/robotics10010022}
}

@online{elhussieny2017inverse,
	author       = {El-Hussieny, Haitham},
	title        = {Lecture 7: Inverse Kinematics},
	year         = {2017},
	url          = {https://bu.edu.eg/portal/uploads/Engineering,%20Shoubra/Electrical%20Engineering/823/crs-14135/Files/lecture7_InverseKinematics.pdf},
	note         = {Apuntes de curso, Faculty of Engineering, Shoubra, Benha University}
}

@article{zhao2024inverse,
	author  = {Zhao, C. and Wei, Y. and Xiao, J. and et al.},
	title   = {Inverse kinematics solution and control method of 6-degree-of-freedom manipulator based on deep reinforcement learning},
	journal = {Scientific Reports},
	volume  = {14},
	pages   = {12467},
	year    = {2024},
	doi     = {10.1038/s41598-024-62948-6},
	url     = {https://doi.org/10.1038/s41598-024-62948-6}
}

@article{adjei2024safe,
	author  = {Patrick Adjei and Norman Tasfi and Santiago Gomez-Rosero and Miriam A. M. Capretz},
	title   = {Safe Reinforcement Learning for Arm Manipulation with Constrained Markov Decision Process},
	journal = {Robotics},
	volume  = {13},
	number  = {4},
	pages   = {63},
	year    = {2024},
	doi     = {10.3390/robotics13040063},
	url     = {https://doi.org/10.3390/robotics13040063}
}

@article{raffin2021stable,
	author = {Raffin, A. and Hill, A. and Gleave, A. and Kanervisto, A. and Ernestus, M. and Dormann, N.},
	title = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
	journal = {Journal of Machine Learning Research},
	volume = {22},
	number = {268},
	pages = {1--8},
	year = {2021}
}

@inproceedings{optuna_2019,
	title={Optuna: A Next-generation Hyperparameter Optimization Framework},
	author={Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
	booktitle={Proceedings of the 25th {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
	year={2019}
}

@article{busy2019qibullet,
	title={qiBullet, a Bullet-based simulator for the Pepper and NAO robots},
	author={Busy, Maxime and Caniot, Maxime},
	journal={arXiv preprint arXiv:1909.00779},
	year={2019}
}

@misc{towers2024gymnasium,
	title={Gymnasium: A Standard Interface for Reinforcement Learning Environments}, 
	author={Mark Towers and Ariel Kwiatkowski and Jordan Terry and John U. Balis and Gianluca De Cola and Tristan Deleu and Manuel Goulão and Andreas Kallinteris and Markus Krimmel and Arjun KG and Rodrigo Perez-Vicente and Andrea Pierré and Sander Schulhoff and Jun Jet Tai and Hannah Tan and Omar G. Younis},
	year={2024},
	eprint={2407.17032},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2407.17032}, 
}